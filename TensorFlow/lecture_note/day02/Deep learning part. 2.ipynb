{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "nbviewer.jupyter.org/format/slides/gist/leechanwoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Day 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Scenario 1. FFNN (Binary): Feed Forward Neural Network\n",
    " * Dataset\n",
    " * Reading Dataset File\n",
    " * Building Model\n",
    " * Model Save/Restore\n",
    " * Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "|label|data0|data1|data2|data3|data4|data5|data6|data7|data8|data9|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|1|2|3|4|5|6|7|8|9|\n",
    "|1|9|8|7|6|5|4|3|2|1|0|\n",
    "|0|0|1|2|3|4|5|6|7|8|9|\n",
    "|1|9|8|7|6|5|4|3|2|1|0|\n",
    "|0|0|1|2|3|4|5|6|7|8|9|\n",
    "|1|9|8|7|6|5|4|3|2|1|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading Dataset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day2/pipeline.gif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building Model\n",
    "\n",
    " * Feed Forward Neural Network(FFNN)\n",
    " * Neural Network 모델 중 가장 기본적인 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$$ y_0 = w_{00}x_0 + w_{01}x_1 + w_{02}x_2 + w_{03}x_3 ... w_{0n}x_n $$\n",
    "$$ y_1 = w_{10}x_0 + w_{11}x_1 + w_{12}x_2 + w_{13}x_3 ... w_{1n}x_n $$\n",
    "$$ y_2 = w_{20}w_0 + w_{21}x_1 + w_{22}x_2 + w_{23}x_3 ... w_{2n}x_n $$\n",
    "$$ y_3 = w_{30}w_0 + w_{31}x_1 + w_{32}x_2 + w_{33}x_3 ... w_{3n}x_n $$\n",
    "$$...$$\n",
    "$$ y_m = w_{m0}x_0 + w_{m1}x_1 + w_{m2}x_2 + w_{m3}x_3 ... w_{mn}x_n $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\begin{bmatrix} y_0\\\\y_1\\\\y_2\\\\y_3\\\\...\\\\y_m \\end{bmatrix} = \\begin{bmatrix} w_{00}&w_{01}&w_{02}&w_{03}&...&w_{0n} \\\\ w_{10}&w_{11}&w_{12}&w_{13}&...&w_{1n} \\\\ w_{20}&w_{21}&w_{22}&w_{23}&...&w_{2n} \\\\ w_{30}&w_{31}&w_{32}&w_{33}&...&w_{3n} \\\\ ...&...&...&...&...&... \\\\ w_{m0}&w_{m1}&w_{m2}&w_{m3}&...&w_{mn} \\end{bmatrix} \\begin{bmatrix} x_0\\\\x_1\\\\x_2\\\\x_3\\\\...\\\\x_n \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ Y^{(1)} = W_1^TX \\cdots 1\\ layer$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ Y^{(2)} = W_2^TY^{(1)} \\cdots 2\\ layer $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ Y^{(3)} = W_3^TY^{(2)} \\cdots 3\\ layer $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * Neural Net 내부의 Layer는 hidden layer라고 부른다.\n",
    " * 각 hidden layer에는 activation function을 취해준다.\n",
    " * 여기서는 sigmoid function을 activation function으로 사용\n",
    " \n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-(wx + b)}} $$ <br>\n",
    "\n",
    "$$ h = \\sigma(W^TX) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ h^{(1)} = \\sigma(W_1^TX) \\cdots 1\\ layer$$ <br>\n",
    "$$ h^{(2)} = \\sigma(W_2^Th^{(1)}) \\cdots 2\\ layer $$ <br>\n",
    "$$ h^{(3)} = \\sigma(W_3^Th^{(2)}) \\cdots 3\\ layer $$ <br>\n",
    "$$ Y = \\sigma(W_o^Th^{(3)}) \\cdots output\\ layer $$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day2/nerual_network_bin.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model save/restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day2/saver.gif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beomyongnho/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) csv file format으로 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "test_samples = 100\n",
    "# 이 ipynb 파일이 있는 폴더에 하위폴더로 ffnn_dataset 폴더를 생성해놔야 함. (아니면 디렉토리 주소를 변경해야...)\n",
    "train_dataset = './ffnn_dataset/train_dataset.csv'\n",
    "test_dataset = './ffnn_dataset/test_dataset.csv'\n",
    "\n",
    "# 아래 함수의 파라미터는 train sample 갯수, test sample 갯수와 각각의 sample data를 저장할 디렉토리를 의미함\n",
    "def write_dataset(samples, test_samples, train_dir, test_dir):\n",
    "    up = [i for i in range(10)]\n",
    "    down = [9-i for i in range(10)]\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "    for i in range(samples):\n",
    "        data.append(up)\n",
    "        data.append(down)\n",
    "        label.append([1])\n",
    "        label.append([0])\n",
    "\n",
    "    with open(train_dataset, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range(samples-test_samples):\n",
    "            writer.writerow(label[i] + data[i])\n",
    "        print('train data is written')\n",
    "\n",
    "    with open(test_dataset, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range(test_samples):\n",
    "            writer.writerow(label[i] + data[i])\n",
    "        print('test data is written')\n",
    "        \n",
    "#write_dataset(1000, 100, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 데이터 불러오기\n",
    "\n",
    "일단 첫 번째로 Dataset 객체를 만들어줘야 하는데, 파일 이름을 쓰는 부분이 있다. \n",
    "여기에는 지금은 그냥 만들어 둔 csv 파일 경로 하나만 넣어놨지만, \n",
    "다수의 파일이 존재 할 경우 [\"file_1.csv\", \"file_2.csv\", \"file_3.csv\" ... \"file_n.csv\"] \n",
    "이렇게 리스트 형태로 넣어줘도 상관없다. \n",
    "데이터 셋 메서드를 이용하여 shuffle과 batching을 아래와 같이 해주면 쉽게 데이터를 얻어올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-49c6b169eb51>:8: TextLineDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.TextLineDataset`.\n",
      "Tensor(\"Cast_2:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"Cast_3:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Cast:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"Cast_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # tensorflow의 graph를 리셋하기 위한 라인\n",
    "\n",
    "# dataset객체를 생성. 파일 경로와 이름을 넣고 batch method로 batching까지 완료(1batch당 data 10개씩)\n",
    "# 다수의 파일이 존재 할 경우 [\"file_1.csv\", \"file_2.csv\", \"file_3.csv\" ... \"file_n.csv\"] 이렇게 리스트 형태로 넣어주는 것도 가능\n",
    "# method를 추가해서 shuffle까지도 구현 가능 \n",
    "# 예: tf.contrib.data.TextLineDataset(test_dataset).shuffle(100).batch(10)\n",
    "\n",
    "trainset = tf.contrib.data.TextLineDataset(train_dataset).batch(10)\n",
    "trainset = trainset.repeat(100)\n",
    "\n",
    "testset = tf.contrib.data.TextLineDataset(test_dataset).batch(10)\n",
    "testset = testset.repeat(99999)\n",
    "\n",
    "\n",
    "\n",
    "# iterator를 만들어주는 부분. \n",
    "# dataset 클래스는 내부에서 queue runners가 동작하는데 iterator는 그 queue에다가 dequeue 요청을 주는 역할을 한다고 보면 된다. \n",
    "# batch가 실행 될 때마다 다음 batch를 얻어온다.\n",
    "train_itr = trainset.make_one_shot_iterator()\n",
    "test_itr = testset.make_one_shot_iterator()\n",
    "# 여기까지가 iterator \n",
    "\n",
    "train_batch = train_itr.get_next()\n",
    "test_batch = test_itr.get_next()\n",
    "# 여기까지가 iterator를 받아 다음 batch를 얻어오기 \n",
    "\n",
    "# text reader로 data를 읽어왔으므로 받아온 data는 string type!\n",
    "# csv를 decode하기만 하면 우리가 원하는 데이터셋을 얻을 수 있음\n",
    "# stack과 expand_dims의 활용은 tensorflow docs를 참고\n",
    "# 아래 코드에서 [[0]]*11는 record_default를 의미하며 missing data 발생 시 이를 채워주는 default value를 설정하는 것\n",
    "train_batch = tf.decode_csv(train_batch, [[0]]*11) \n",
    "test_batch = tf.decode_csv(test_batch, [[0]]*11)\n",
    "\n",
    "y_ = tf.reshape(train_batch[0], [-1, 1]) \n",
    "# 위 라인에서 train_batch[0]은 'column index=0'을 numpy ndarray로 받음. [1 0 ... 0 1] 형태임. \n",
    "# [-1, 1]은 reshape 과정에서 행의 갯수는 따로 지정하지 않고 열의 갯수는 1개로 지정함을 의미\n",
    "test_label = tf.reshape(test_batch[0], [-1, 1])\n",
    "\n",
    "x = tf.stack(train_batch[1:], axis=1)\n",
    "test_data = tf.stack(test_batch[1:], axis=1)\n",
    "\n",
    "# 마지막으로 머신러닝 모델에서 연산을 수행 하기 위해선 이렇게 float type으로 casting 해주면 된다.\n",
    "# 이 과정을 빼먹으면 dtype = int32가 되어 사칙연산이 제대로 수행되지 않는다.(불가여부는?)\n",
    "test_label = tf.cast(test_label, tf.float32)\n",
    "test_input = tf.cast(test_data, tf.float32)\n",
    "y_ = tf.cast(y_, tf.float32)\n",
    "x = tf.cast(x, tf.float32)\n",
    "\n",
    "print(y_)\n",
    "print(x)\n",
    "print(test_label)\n",
    "print(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define과정에서 데이터는 다음과 같이 출력해서 확인해보는 것이 좋다. \n",
    "# with tf.Session() as sess:\n",
    "#     _a= sess.run(y_)\n",
    "#     print(_a)\n",
    "#     print(type(_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def bin_model(x, activation=None, reuse=False):\n",
    "    # dense method는 fully connected 모델을 생성함을 의미한다. \n",
    "    # x는 input data\n",
    "    # activation은 말 그대로 activation function\n",
    "    # reuse는 Boolean type keyword parameter로 previous layer의 가중치 재사용 여부를 결정. test data로 검증할 때 reuse \n",
    "    layer1 = tf.layers.dense(x, 10, activation=activation, reuse=reuse, name='layer1')\n",
    "    layer2 = tf.layers.dense(layer1, 10, activation=activation, reuse=reuse, name='layer2')\n",
    "    layer3 = tf.layers.dense(layer2, 10, activation=activation, reuse=reuse, name='layer3')\n",
    "    layer4 = tf.layers.dense(layer3, 10, activation=activation, reuse=reuse, name='layer4')\n",
    "    out = tf.layers.dense(layer4, 1, reuse=reuse, name='out')\n",
    "    print('layer1 shape {}'.format(layer1.shape))\n",
    "    print('layer2 shape {}'.format(layer2.shape))\n",
    "    print('layer3 shape {}'.format(layer3.shape))\n",
    "    print('layer4 shape {}'.format(layer4.shape))\n",
    "    print('out shape {}'.format(out.shape))\n",
    "    return out\n",
    "    \n",
    "train_out = bin_model(x, activation=tf.nn.sigmoid)\n",
    "test_out = bin_model(test_input, activation=tf.nn.sigmoid, reuse=True)\n",
    "# test data의 경우 training data로 fitting해서 구한 가중치를 그대로 사용해서 결과를 도출해야 하므로 reuse=True가 된다. \n",
    "\n",
    "# variable들(즉, weights(가중치)들의 shape을 살펴보기 위한 코드(input과 output의 shape에 따라 달라짐) \n",
    "for var in tf.trainable_variables():\n",
    "    print(var)\n",
    "    \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "loss = tf.losses.sigmoid_cross_entropy(y_, train_out) #loss function과 activation function은 다르다\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(test_out)\n",
    "accuracy = tf.metrics.accuracy(test_label, tf.round(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss', loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./ffnn_logs/', sess.graph)\n",
    "    for i in range(1000):\n",
    "        try:\n",
    "            _, _loss, _acc, _summ = sess.run([train_op, loss, accuracy, merged])\n",
    "            writer.add_summary(_summ, i)\n",
    "            if i%100 == 0:\n",
    "                _pred = sess.run(pred)\n",
    "                print('step: {}, loss: {}, acc: {}'.format(i, _loss, _acc[0]))\n",
    "        \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    saver.save(sess, './ffnn_logs/ffnn')\n",
    "    \n",
    "#prediction\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './ffnn_logs/ffnn')\n",
    "    _pred = sess.run(pred)\n",
    "    print(_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scenario 2. FFNN(Multi-class)\n",
    " * Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day2/neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beomyongnho/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "train data is written\n",
      "test data is written\n"
     ]
    }
   ],
   "source": [
    "samples = 1000\n",
    "test_samples = 100\n",
    "train_dataset = './ffnn_multiclass_dataset/train_dataset.csv'\n",
    "test_dataset = './ffnn_multiclass_dataset/test_dataset.csv'\n",
    "\n",
    "up = [i for i in range(10)]\n",
    "down = [9-i for i in range(10)]\n",
    "flat = [5 for i in range(10)]\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "for i in range(samples):\n",
    "    data.append(up)\n",
    "    data.append(flat)\n",
    "    data.append(down)\n",
    "    label.append([0])\n",
    "    label.append([1])\n",
    "    label.append([2])\n",
    "    \n",
    "for i in range(10):\n",
    "    print('data: {}, label {}'.format(data[i], label[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "with open(train_dataset, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(samples-test_samples):\n",
    "        writer.writerow(label[i] + data[i])\n",
    "    print('train data is written')\n",
    "        \n",
    "with open(test_dataset, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(test_samples):\n",
    "        writer.writerow(label[i] + data[i])\n",
    "    print('test data is written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   10\n",
       "895   1   5   5   5   5   5   5   5   5   5   5\n",
       "896   2   9   8   7   6   5   4   3   2   1   0\n",
       "897   0   0   1   2   3   4   5   6   7   8   9\n",
       "898   1   5   5   5   5   5   5   5   5   5   5\n",
       "899   2   9   8   7   6   5   4   3   2   1   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./ffnn_multiclass_dataset/train_dataset.csv', header = None)\n",
    "test_df = pd.read_csv('./ffnn_multiclass_dataset/test_dataset.csv', header = None)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10\n",
       "95   2   9   8   7   6   5   4   3   2   1   0\n",
       "96   0   0   1   2   3   4   5   6   7   8   9\n",
       "97   1   5   5   5   5   5   5   5   5   5   5\n",
       "98   2   9   8   7   6   5   4   3   2   1   0\n",
       "99   0   0   1   2   3   4   5   6   7   8   9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-182347d426a5>:2: TextLineDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.TextLineDataset`.\n",
      "Tensor(\"Cast_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Cast:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"one_hot:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainset = tf.contrib.data.TextLineDataset(train_dataset).batch(10)\n",
    "testset = tf.contrib.data.TextLineDataset(test_dataset).batch(10)\n",
    "\n",
    "train_itr = trainset.make_one_shot_iterator()\n",
    "test_itr = testset.make_one_shot_iterator()\n",
    "\n",
    "train_batch = train_itr.get_next()\n",
    "test_batch = test_itr.get_next()\n",
    "\n",
    "decoded_train = tf.decode_csv(train_batch, [[0]]*11)\n",
    "decoded_test = tf.decode_csv(test_batch, [[0]]*11)\n",
    "\n",
    "train_label = tf.one_hot(decoded_train[0], depth=3, axis=-1, dtype=tf.float32)\n",
    "test_label = tf.reshape(decoded_test[0], [-1, 1])\n",
    "\n",
    "train_data = tf.stack(decoded_train[1:], axis=1)\n",
    "test_data = tf.stack(decoded_test[1:], axis=1)\n",
    "\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a527cfa19918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'layer_out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_class_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_class_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "def multi_class_model(x, activation, reuse=False):\n",
    "    layer1 = tf.layers.dense(x, 10, activation=activation, reuse=reuse, name='layer1')\n",
    "    layer2 = tf.layers.dense(layer1, 10, activation=activation, reuse=reuse, name='layer2')\n",
    "    layer3 = tf.layers.dense(layer2, 10, activation=activation, reuse=reuse, name='layer3')\n",
    "    layer4 = tf.layers.dense(layer3, 10, activation=activation, reuse=reuse, name='layer4')\n",
    "    return tf.layers.dense(layer4, 3, activation=activation, reuse=reuse, name='layer_out')\n",
    "\n",
    "train_out = multi_class_model(train_data, tf.nn.sigmoid)\n",
    "test_out = multi_class_model(test_data, tf.nn.sigmoid, True)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(train_label, train_out)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-6).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(test_out)\n",
    "accuracy = tf.metrics.accuracy(test_label, tf.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.1010239124298096, acc: 0.3333333432674408\n",
      "epoch: 1, loss: 1.1008332967758179, acc: 0.3333333432674408\n",
      "epoch: 2, loss: 1.1377357244491577, acc: 0.3333333432674408\n",
      "epoch: 3, loss: 1.1010239124298096, acc: 0.3333333432674408\n",
      "epoch: 4, loss: 1.1008331775665283, acc: 0.3333333432674408\n",
      "epoch: 5, loss: 1.1377357244491577, acc: 0.3333333432674408\n",
      "epoch: 6, loss: 1.1010239124298096, acc: 0.3333333432674408\n",
      "epoch: 7, loss: 1.1008332967758179, acc: 0.3333333432674408\n",
      "epoch: 8, loss: 1.1377357244491577, acc: 0.3333333432674408\n",
      "epoch: 9, loss: 1.1010239124298096, acc: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(10):\n",
    "        while True:\n",
    "            try:\n",
    "                _, _loss = sess.run([train_op, loss])\n",
    "                _acc = sess.run(accuracy)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        print('epoch: {}, loss: {}, acc: {}'.format(i, _loss, _acc[0]))\n",
    "        saver.save(sess, './logs/model')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
