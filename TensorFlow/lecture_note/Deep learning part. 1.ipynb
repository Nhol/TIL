{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "nbviewer.jupyter.org/format/slides/gist/leechanwoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Day 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture Intro.\n",
    " * Introduction\n",
    " * How we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "### 이 찬 우  \n",
    " - cjswosa2@naver.com\n",
    " - gist.github.com/leechanwoo\n",
    "\n",
    "#### 강의\n",
    " - 패스트캠퍼스 Deep Learning 과정\n",
    " - 멀티캠퍼스 Deep Learning 과정\n",
    " - Udemy Data Scientist 강의(예정)\n",
    " - Youtube 딥러닝 이론 강의\n",
    " - Youtube 텐서플로 라이브 강의\n",
    " - 화상 원격 강의\n",
    "\n",
    "#### 약력\n",
    " - 현 모두의 연구소 - NLP 연구원\n",
    " - 현 OrbisAI - Data Scientist\n",
    " - 전 Lifesemantics - Data Scientist\n",
    " - 전 SynapseImaging - Machine Vision Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How we learn?\n",
    "\n",
    " - Coding Together!\n",
    " - 하드디스크가 기억하는 코드? 손이 기억하는 코드!\n",
    " - 공연에서는 앵콜, 강의에서는 질문\n",
    " - 집단지성의 힘! 실습간 적극적인 토론, 토의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Intro.\n",
    " * How machines learn?\n",
    " * What is Neural Network\n",
    " * What is Loss function\n",
    " * What is Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How machines learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = ax $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "여기서 가장 적절한 a값을 찾아내는 것이 Machine Learning의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "학습 간 a값 Update 과정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$y = ax$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$a' = grad(y', y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$a = a - a'$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$y = ax$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### exmaple\n",
    "\n",
    "| data | label |\n",
    "|:----:|:-----:|\n",
    "|  1   |   2   |\n",
    "|  2   |   4   |\n",
    "|  3   |   6   |\n",
    "|  4   |   8   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "적절한 난수로 a값 초기화\n",
    "\n",
    "$$y = 0.5x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "data = 1을 넣어서 prediction\n",
    "\n",
    "$$0.5 = 0.5 \\times 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "prediction과 label 비교하여 a의 변화량 계산(grad는 나중에 다룰 것!)\n",
    "\n",
    "$$-0.6 = grad(2, 0.5)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "a update\n",
    "\n",
    "$$ 1.1 = 0.5 - (-0.6)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "학습된 모델\n",
    "\n",
    "$$y = 1.1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "반복 data = 2, label = 4\n",
    "\n",
    "$$ y = 1.1x $$ <br>\n",
    "$$ 2.2 = 1.1 * 2 $$ <br>\n",
    "$$ -0.5 = grad(4, 2.2) $$ <br>\n",
    "$$ 1.6 = 1.1 -(-0.5) $$ <br>\n",
    "$$ y = 1.6x $$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "반복 data = 3, label = 6\n",
    "\n",
    "$$ y = 1.6x $$ <br>\n",
    "$$ 4.8 = 1.6 * 3 $$ <br>\n",
    "$$ -0.3 = grad(6, 4.8) $$ <br>\n",
    "$$ 1.9 = 1.6 -(-0.3) $$ <br>\n",
    "$$ y = 1.9x $$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "반복 data = 4, label = 8\n",
    "\n",
    "$$ y = 1.9x $$ <br>\n",
    "$$ 7.6 = 1.9 * 4 $$ <br>\n",
    "$$ -0.1 = grad(8, 7.6) $$ <br>\n",
    "$$ 2 = 1.9 - (-0.1) $$ <br> \n",
    "$$ y = 2x $$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = ax $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = a_0x_0 + a_1x_1 + a_2x_2 + a_3x_3 ... a_nx_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$y = w_0x_0 + w_1x_1 + w_2x_2 + w_3x_3 ... w_nx_n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "./day1/neurons1.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('./day1/neurons1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ y_0 = w_{00}x_0 + w_{01}x_1 + w_{02}x_2 + w_{03}x_3 ... w_{0n}x_n $$\n",
    "$$ y_1 = w_{10}x_0 + w_{11}x_1 + w_{12}x_2 + w_{13}x_3 ... w_{1n}x_n $$\n",
    "$$ y_2 = w_{20}w_0 + w_{21}x_1 + w_{22}x_2 + w_{23}x_3 ... w_{2n}x_n $$\n",
    "$$ y_3 = w_{30}w_0 + w_{31}x_1 + w_{32}x_2 + w_{33}x_3 ... w_{3n}x_n $$\n",
    "$$...$$\n",
    "$$ y_m = w_{m0}x_0 + w_{m1}x_1 + w_{m2}x_2 + w_{m3}x_3 ... w_{mn}x_n $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "./day1/neurons2.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('./day1/neurons2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Loss function\n",
    "\n",
    " * 예측을 얼마나 실패했는지를 나타내는 수치\n",
    " * Label 기준 Prediction이 틀릴수록 loss가 커짐\n",
    " * Label 기준 prediction이 일치 할 수록 loss는 0에 가까워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ if\\ label = prediction \\ \\cdots \\ loss \\ \\rightarrow \\  0 $$\n",
    "$$ if\\ label \\neq prediction \\ \\cdots \\ loss \\ \\rightarrow \\ \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ mean\\ squared\\ error = \\frac{1}{2}(y' - y)^2 $$ <br>\n",
    "$$ cross\\ entropy = -y'log(y) - (1-y')log(1-y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Optimizer\n",
    "\n",
    "$$ w = w^- - \\alpha\\frac{\\partial{L}}{\\partial{w}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Tensorflow Intro.\n",
    " * What is Tensorflow\n",
    " * Why is Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Tensorflow\n",
    "\n",
    " * Caffe, Torch, PyTorch, MXNet, CNTK 등과 같이 딥러닝 모델을 효과적으로 설계할 수 있도록 설계된 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beomyongnho/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello tensorflow!!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "const = tf.constant('hello tensorflow!!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _const = sess.run(const)\n",
    "    print(_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why is Tensorflow\n",
    "\n",
    " * GPU를 효과적으로 활용 할 수 있도록 하여 연산 속도를 보장하면서 성능 강하 최소화 → 프레임워크의 경쟁력\n",
    "\n",
    " * 연구자가 쉽게 코드를 생산 할 수 있도록 여러가지 Wrapper를 제공\n",
    "\n",
    " * 매우 유연한 개발환경 → Mobile, Backend, Cloud, RaspberryPi 등 포팅 가능, 일반 어플리케이션과 유사하게 모델 배포, 서비스 지원\n",
    "\n",
    " * Google Cloud Platform에서 더욱 쉽게 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow Basic\n",
    " * Define and Run\n",
    " * Graph\n",
    " * Session\n",
    " * constant\n",
    " * placeholder\n",
    " * Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define and Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define by Run at Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello python!\n"
     ]
    }
   ],
   "source": [
    "_list = 'hello python!'\n",
    "print(_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define and Run at Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello tensorflow!!'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Define and Run at tensorflow\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define\n",
    "const = tf.constant('hello tensorflow!!')\n",
    "\n",
    "# Run\n",
    "with tf.Session() as sess:\n",
    "    _const = sess.run(const)\n",
    "    print(_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " * Define된 모든 Tensor, Operator \n",
    " * 연산 구조를 각 Tensor, Operator가 Node로 이루어진 Graph로 정의\n",
    " * Session을 통해서 실행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=string)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_string = tf.constant('hello tensorflow')\n",
    "tf_int = tf.constant(10)\n",
    "tf_float = tf.constant(3.14)\n",
    "\n",
    "print(tf_string)\n",
    "print(tf_int)\n",
    "print(tf_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "one = tf.constant([[1, 1, 1]])\n",
    "two = tf.constant([[2], [2], [2]])\n",
    "\n",
    "matmul = tf.matmul(one, two)\n",
    "print(matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Session\n",
    "\n",
    " * Define된 Graph의 연산을 수행\n",
    " * CPU, GPU 선택적 연산 수행 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_string = tf.constant('hello tensorflow')\n",
    "tf_int = tf.constant(10)\n",
    "tf_float = tf.constant(3.14)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _tf_string = sess.run(tf_string)\n",
    "    _tf_int = sess.run(tf_int)\n",
    "    _tf_float = sess.run(tf_float)\n",
    "    \n",
    "    print(_tf_string)\n",
    "    print(_tf_int)\n",
    "    print(_tf_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "one = tf.constant([[1, 1, 1]])\n",
    "two = tf.constant([[2], [2], [2]])\n",
    "\n",
    "matmul = tf.matmul(one, two)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _matmul = sess.run(matmul)\n",
    "    print(_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "one = tf.constant([[1, 1, 1]])\n",
    "two = tf.constant([[2], [2], [2]])\n",
    "\n",
    "matmul = tf.matmul(one, two)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _one, _two, _matmul = sess.run([one, two, matmul])\n",
    "    print(_one)\n",
    "    print(_two)\n",
    "    print(_matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "const = tf.constant(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "pl_data = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pl_data, {pl_data: data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "var = tf.Variable(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scenario 1. Linear Regression\n",
    " * Generating Data\n",
    " * Buiding Model\n",
    " * Training Model\n",
    " * Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generating Data\n",
    "\n",
    "현실 데이터와 유사하게 학습용 시뮬레이션 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/dataset.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Buiding Model\n",
    "\n",
    "$$ y = wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/ax_b_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/ax_b_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Model\n",
    "\n",
    "Loss 함수를 이용하여 label과 prediction의 차이를 계산\n",
    "\n",
    "$$ L(y', y) = \\frac{1}{2m}\\sum_{n=1}^{m}(y_n' - y_n)^2 \\cdots mean\\ squared\\ error $$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/loss_fn_1.gif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "최적의 w값을 찾는다 = loss 함수의 최소값에 해당하는 w값을 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/loss_fn_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "최소값 찾는 방법 $\\rightarrow$ Gradient Descent Optimizer\n",
    "\n",
    "$$w = w^- - \\alpha\\frac{\\partial{L}}{\\partial{w_n}}$$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/gradientdes.gif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "기울기가 너무 클 경우 $ w \\rightarrow \\infty $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "./day1/infw.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('./day1/infw.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "기울기에 작은 수를 곱해주어 weight 변화량 조절 $\\rightarrow$ learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/learning_rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implemetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "data = np.array([1e-3*float(i) for i in range(samples)])\n",
    "label = 4.2 * data + 2.2 + np.random.randn(samples)\n",
    "target = 4.2 * data + 2.2\n",
    "\n",
    "plt.figure(11)\n",
    "plt.ylim(-2, 10)\n",
    "plt.scatter(data, label, 1, 'r')\n",
    "plt.figure(21)\n",
    "plt.ylim(-2, 10)\n",
    "plt.scatter(data, target, 1, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y_ = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "y = w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_, y)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        _, _loss = sess.run([train_op, loss], feed_dict={x: data, y_: label})\n",
    "        if i%10 == 0:\n",
    "            print('step: {}, loss: {}'.format(i, _loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scenario 2. Logistic Regression\n",
    " * Generating Data\n",
    " * Buiding Model\n",
    " * Training Model\n",
    " * Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generating Data\n",
    "\n",
    "현실 데이터와 유사하게 학습용 시뮬레이션 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/logistic_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Buiding Model\n",
    "\n",
    " * Logistic 문제에서는 label $\\rightarrow$ 0 or 1 \n",
    " * Sigmoid Function을 이용하여 Fitting\n",
    "\n",
    "$$ y = \\frac{1}{1 + e^{-(wx + b)}} $$ <br>\n",
    "\n",
    "$$ y = \\sigma(wx + b) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/./sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/sig_ax_b.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Model\n",
    "\n",
    "Loss 함수를 이용하여 label과 prediction의 차이를 계산\n",
    "\n",
    "$$ L(y', y) = \\frac{1}{m}\\sum_{n=1}^{m}-y'log(y) - (1-y')log(1-y) \\cdots cross\\ entropy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ -y'log(y) \\cdots if\\ y' = 1$$ <br>\n",
    "$$ -(1-y')log(1-y) \\cdots if\\ y' = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./day1/cross_entropy2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "samples = 1000\n",
    "data = [float(i)*0.01 for i in range(-samples, samples)]\n",
    "label = [1 if i>2.5 else 0 for i in data]\n",
    "\n",
    "plt.plot(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y_ = tf.placeholder(tf.float32)\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "y = a*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(y_, y)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        _, _loss = sess.run([train_op, loss], feed_dict={x: data, y_: label})\n",
    "        if i%10 == 0:\n",
    "            print('step: {}, loss: {}'.format(i, _loss))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
