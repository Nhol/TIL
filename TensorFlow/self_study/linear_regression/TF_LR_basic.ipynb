{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강의 참고자료\n",
    "\n",
    "<Andrew Ng's ML class>\n",
    "\n",
    "https://class.coursera.org/ml-003/lecture\n",
    "\n",
    "http://www.holehouse.org/mlclass/ (강의노트)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) ML lec & lab 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Flow의 개념\n",
    "\n",
    "- data flow graph를 이용해서 numerical computation을 한다.\n",
    "\n",
    "- data flow graph는?\n",
    "    Nodes: 그래프 안에서 원(타원)안에 들어있는 부분. 수학적인 연산을 의미\n",
    "    Edges: 그래프 안에서 원을 연결하면서 흐름을 나타내는 선.  multidimensional data arrays(=tensor) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow 설치 여부 및 version 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hello TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello = tf.constant(\"Hello TensorFlow\")\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    _hello = sess.run(hello)\n",
    "    print(_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0, tf.float32)\n",
    "node3 = tf.add(node1, node2)\n",
    "# node4 = node1 + node2 (tf.add와 동일한 결과)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(node1)\n",
    "print(node2)\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print('node1 and node2 are respectively', sess.run([node1, node2]))\n",
    "print('node3 is ', sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 build 한다. (tf.constant 등의 define 과정)\n",
    "그래프를 실행한다. (sess.run)\n",
    "실행의 결과로 그래프 안의 값들이 업데이트 되거나 리턴된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder, variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a:3, b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 만들어 놓고 나면 placeholder를 이용해서 필요한 데이터를 node에 전달하여 하고자 하는 연산의 결과값을 받을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ML lec & lab 02: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = [1, 2, 3] 에 상응하는 y=[1, 2, 3] \n",
    "\n",
    "이 때 선형회귀방법으로 w를 추정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x, y data\n",
    "x = [1, 2, 3]\n",
    "y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis: y = W*x + b\n",
    "yhat = W*x + b\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))\n",
    "\n",
    "# Optimizer: cost function값의 최소화\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # variable w, b를 사용하기 위함\n",
    "    for i in range(2001):\n",
    "        sess.run(train)\n",
    "        if i %200==0:\n",
    "            print('step: {}, cost: {}, w: {}, b: {}'\n",
    "                  .format(i, sess.run(cost), sess.run(W), sess.run(b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### placeholder를 이용한 데이터 전달 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis: y = W*x + b\n",
    "yhat = W*X + b\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))\n",
    "\n",
    "# Optimizer: cost function값의 최소화\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # variable w, b를 사용하기 위함\n",
    "for i in range(2001):\n",
    "    _cost, _W, _b, _ = sess.run([cost, W, b, train], \n",
    "                                feed_dict={X: [1, 2, 3, 4, 5], y:[2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if i %200==0:\n",
    "        print('step: {}, cost: {}, W: {}, b: {}'\n",
    "                .format(i, _cost, _W, _b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing(검증): W = 1, b =1.1에 가까우면 잘 된 예측으로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(yhat, feed_dict={X: [5]}))\n",
    "print(sess.run(yhat, feed_dict={X: [6, 7, 8]}))\n",
    "print(sess.run(yhat, feed_dict={X: [2.5, 3.5, 4.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) ML lec & lab 03\n",
    "\n",
    "### Linear Regression의 cost function 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잔차제곱의 평균으로 정의된 cost function cost(W, b)을 그래프로 그려보면 포물선 형태의 곡선이 된다. (b=0으로 가정하여 단순화했을 때)\n",
    "\n",
    "이 곡선에서 cost(W, b)가 최소가 되는 W, b를 찾는 것\n",
    "\n",
    "어떻게 cost(W, b)가 최소가 되는 지점을 찾을 것인가? => Gradient Descent algorithm\n",
    "\n",
    "cost function의 형태가 convex function이면 어느 점에서 시작해도 cost function의 최저점을 찾을 수 있다. 하지만 비용함수가 convex function이 아닐 경우 시작 위치에 따라 비용함수 최저값이 다를게 나타날 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3]\n",
    "y = [1, 2, 3]\n",
    "W = tf.placeholder(tf.float32)\n",
    "yhat = W*X\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "W_val = []\n",
    "cost_val =[]\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W를 변화시켜가며 직접 cost 최저점 찾아보기\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "X_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), tf.float32, name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "yhat = X*W\n",
    "cost = tf.reduce_sum(tf.square(yhat-y)) #직접 찾아보려고 .minimize 사용하지 않음\n",
    "\n",
    "# 수동으로 cost minimize 하기\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*y - y)*X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: X_data, y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: X_data, y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TF code 연습\n",
    "import tensorflow as tf\n",
    "X_data = [1, 2, 3]\n",
    "y_data = [2, 4, 6]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "yhat = W*X + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5000):\n",
    "        _, _cost, _W, _b = sess.run([train, cost, W, b],\n",
    "                                   feed_dict={X: X_data, y: y_data})\n",
    "        if i%100==0:\n",
    "            print('step: {}, cost: {}, Weight: {}, bias: {}'\n",
    "                 .format(i, _cost, _W, _b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1) ML lec & lab 04\n",
    "\n",
    "### Multivariable linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hypothesis: \n",
    "$$\n",
    "H(x) = Wx + b\n",
    "$$\n",
    "$$\n",
    "H(x_{1}, x_{2}, x_{3}) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b\n",
    "$$\n",
    "\n",
    "\n",
    "- Cost function, Gradient descent algorithm 은 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_data = [73, 93, 89, 96, 73]\n",
    "x2_data = [80, 88, 91, 98, 66]\n",
    "x3_data = [75, 93, 90, 100, 70]\n",
    "y_data = [152, 185, 180, 196, 142]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "yhat = x1*w1 + x2*w2 + x3*w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-05)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2001):\n",
    "    _, _cost, _yhat = sess.run([train, cost, yhat], \n",
    "                        feed_dict={x1: x1_data, \n",
    "                                   x2: x2_data,\n",
    "                                   x3: x3_data, \n",
    "                                   y: y_data})\n",
    "    if i%200==0:\n",
    "        print('cost: {}, predict: {}'.format(_cost, _yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 하지만 이런 방법은 변수나 데이터 갯수가 늘어날 경우 코드가 매우 복잡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x_data = np.vstack((x1_data, x2_data, x3_data)).T\n",
    "y_data = np.array(y_data).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "yhat = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(yhat - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-05)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 157.6249542236328, pred[[ 154.50639343]\n",
      " [ 201.94659424]\n",
      " [ 190.58752441]\n",
      " [ 209.56750488]\n",
      " [ 156.08839417]]\n",
      "step: 100, cost: 20.109107971191406, pred[[ 144.31492615]\n",
      " [ 189.36993408]\n",
      " [ 178.36618042]\n",
      " [ 196.23428345]\n",
      " [ 146.43447876]]\n",
      "step: 200, cost: 19.108577728271484, pred[[ 144.48399353]\n",
      " [ 189.25454712]\n",
      " [ 178.41860962]\n",
      " [ 196.2674408 ]\n",
      " [ 146.28707886]]\n",
      "step: 300, cost: 18.16060447692871, pred[[ 144.64857483]\n",
      " [ 189.14219666]\n",
      " [ 178.46965027]\n",
      " [ 196.29957581]\n",
      " [ 146.14367676]]\n",
      "step: 400, cost: 17.262346267700195, pred[[ 144.80882263]\n",
      " [ 189.03282166]\n",
      " [ 178.5193634 ]\n",
      " [ 196.33079529]\n",
      " [ 146.00416565]]\n",
      "step: 500, cost: 16.411285400390625, pred[[ 144.96482849]\n",
      " [ 188.92634583]\n",
      " [ 178.56776428]\n",
      " [ 196.36105347]\n",
      " [ 145.86845398]]\n",
      "step: 600, cost: 15.604881286621094, pred[[ 145.116745  ]\n",
      " [ 188.82272339]\n",
      " [ 178.61494446]\n",
      " [ 196.39044189]\n",
      " [ 145.73646545]]\n",
      "step: 700, cost: 14.84077262878418, pred[[ 145.26461792]\n",
      " [ 188.72180176]\n",
      " [ 178.66085815]\n",
      " [ 196.41891479]\n",
      " [ 145.60803223]]\n",
      "step: 800, cost: 14.116731643676758, pred[[ 145.40861511]\n",
      " [ 188.62358093]\n",
      " [ 178.70558167]\n",
      " [ 196.44654846]\n",
      " [ 145.48310852]]\n",
      "step: 900, cost: 13.430712699890137, pred[[ 145.54878235]\n",
      " [ 188.52793884]\n",
      " [ 178.74913025]\n",
      " [ 196.4733429 ]\n",
      " [ 145.36158752]]\n",
      "step: 1000, cost: 12.780560493469238, pred[[ 145.68530273]\n",
      " [ 188.43484497]\n",
      " [ 178.79156494]\n",
      " [ 196.49932861]\n",
      " [ 145.24339294]]\n",
      "step: 1100, cost: 12.16456127166748, pred[[ 145.81819153]\n",
      " [ 188.34420776]\n",
      " [ 178.83288574]\n",
      " [ 196.52456665]\n",
      " [ 145.12841797]]\n",
      "step: 1200, cost: 11.580789566040039, pred[[ 145.94758606]\n",
      " [ 188.25596619]\n",
      " [ 178.87312317]\n",
      " [ 196.54896545]\n",
      " [ 145.01657104]]\n",
      "step: 1300, cost: 11.027637481689453, pred[[ 146.07357788]\n",
      " [ 188.17007446]\n",
      " [ 178.912323  ]\n",
      " [ 196.57267761]\n",
      " [ 144.9078064 ]]\n",
      "step: 1400, cost: 10.503398895263672, pred[[ 146.19624329]\n",
      " [ 188.08644104]\n",
      " [ 178.95050049]\n",
      " [ 196.59564209]\n",
      " [ 144.80197144]]\n",
      "step: 1500, cost: 10.00660514831543, pred[[ 146.31570435]\n",
      " [ 188.0050354 ]\n",
      " [ 178.98771667]\n",
      " [ 196.61790466]\n",
      " [ 144.69908142]]\n",
      "step: 1600, cost: 9.535780906677246, pred[[ 146.43202209]\n",
      " [ 187.92578125]\n",
      " [ 179.0239563 ]\n",
      " [ 196.63949585]\n",
      " [ 144.59898376]]\n",
      "step: 1700, cost: 9.089601516723633, pred[[ 146.54525757]\n",
      " [ 187.84860229]\n",
      " [ 179.05923462]\n",
      " [ 196.66040039]\n",
      " [ 144.50161743]]\n",
      "step: 1800, cost: 8.666704177856445, pred[[ 146.65553284]\n",
      " [ 187.77346802]\n",
      " [ 179.09362793]\n",
      " [ 196.6806488 ]\n",
      " [ 144.40692139]]\n",
      "step: 1900, cost: 8.265909194946289, pred[[ 146.76290894]\n",
      " [ 187.70031738]\n",
      " [ 179.12710571]\n",
      " [ 196.70027161]\n",
      " [ 144.31481934]]\n",
      "step: 2000, cost: 7.8860764503479, pred[[ 146.86746216]\n",
      " [ 187.62911987]\n",
      " [ 179.159729  ]\n",
      " [ 196.71928406]\n",
      " [ 144.22525024]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2001):\n",
    "    _, _cost, _yhat = sess.run([train_op, cost, yhat], \n",
    "                              feed_dict={X: x_data,\n",
    "                                         y: y_data})\n",
    "    if i%100==0:\n",
    "        print('step: {}, cost: {}, pred{}'.format(i, _cost, _yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My score will be [[ 192.46980286]]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 데이터 추가하여 예측\n",
    "print('My score will be', \n",
    "      sess.run(yhat, feed_dict={X: [[100, 96, 92]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2) ML lec & lab 04\n",
    "\n",
    "- Multivariable linear regression\n",
    "- Data를 csv파일에서 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beomyongnho/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "x_data = np.vstack((x1_data, x2_data, x3_data)).T\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "y_data = np.array(y_data).reshape([-1,1])\n",
    "dataset = np.hstack((x_data, y_data))\n",
    "\n",
    "x_dataset = './data/X_dataset.csv'\n",
    "with open(x_dataset, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(dataset)):\n",
    "        writer.writerow(dataset[i])\n",
    "    print('X_dataset is written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data/X_dataset.csv', delimiter=',', dtype=np.float32)\n",
    "x_dataset = xy[:, 0:-1]\n",
    "y_dataset = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) [[  73.   80.   75.]\n",
      " [  93.   88.   93.]\n",
      " [  89.   91.   90.]\n",
      " [  96.   98.  100.]\n",
      " [  73.   66.   70.]] 5\n",
      "(5, 1) [[ 152.]\n",
      " [ 185.]\n",
      " [ 180.]\n",
      " [ 196.]\n",
      " [ 142.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_dataset.shape, x_dataset, len(x_dataset))\n",
    "print(y_dataset.shape, y_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이하 linear regression 방법은 앞서 진행한 것과 동일하므로 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4-3) Queue Runner\n",
    "\n",
    "file 용량이 커서 한번에 메모리에 올리지 못할 경우 사용. 다음의 세 단계로 이뤄짐\n",
    "\n",
    "1) filename_queue\n",
    "\n",
    "2) reader\n",
    "\n",
    "3) record_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 예시\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data1.csv', 'data2.csv', ...], \n",
    "    shuffle=False, \n",
    "    name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(finlename_queue)\n",
    "\n",
    "record_dafaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
